# ScraperMaster API

Una API avanzada de web scraping que utiliza FastAPI y Playwright para extraer contenido web y convertirlo a markdown de forma organizada y estructurada.

## ğŸš€ CaracterÃ­sticas

- **Web Scraping Inteligente**: Utiliza Playwright para renderizar pÃ¡ginas dinÃ¡micas
- **ConversiÃ³n a Markdown**: Convierte contenido HTML a markdown limpio y organizado
- **ExtracciÃ³n de Datos**: Detecta automÃ¡ticamente montos, fechas, contactos y datos estructurados
- **AnÃ¡lisis de Contenido**: Organiza tablas, listas, encabezados e imÃ¡genes
- **API RESTful**: Endpoints bien documentados con validaciÃ³n de datos
- **Containerizado**: Listo para deployment con Docker

## ğŸ“‹ Requisitos

- Python 3.11 o superior
- FastAPI
- Playwright
- BeautifulSoup4
- Docker (opcional)

## ğŸ› ï¸ InstalaciÃ³n

### OpciÃ³n 1: InstalaciÃ³n Local

1. Clona este repositorio:

```bash
git clone <repository-url>
cd scrapermaster-api
```

2. Instala las dependencias:

```bash
pip install -r requirements.txt
```

3. Instala los navegadores de Playwright:

```bash
playwright install chromium
```

4. Ejecuta la aplicaciÃ³n:

```bash
uvicorn main:app --reload
```

### OpciÃ³n 2: Docker

1. Construye la imagen:

```bash
docker build -t scrapermaster-api .
```

2. Ejecuta el contenedor:

```bash
docker run -p 8000:8000 scrapermaster-api
```

### OpciÃ³n 3: Docker Compose

```bash
docker-compose up --build
```

## EjecuciÃ³n

### EjecuciÃ³n Local

Ejecuta el servidor con el siguiente comando:

```bash
uvicorn main:app --reload
```

### EjecuciÃ³n con Docker

```bash
docker-compose up
```

La API estarÃ¡ disponible en `http://127.0.0.1:8000`.

## Endpoints

- `GET /` - Endpoint principal que devuelve un mensaje de bienvenida
- `GET /.well-known/appspecific/com.chrome.devtools.json` - ConfiguraciÃ³n para Chrome DevTools

## DocumentaciÃ³n de la API

Una vez que la aplicaciÃ³n estÃ© ejecutÃ¡ndose, puedes acceder a:

- **DocumentaciÃ³n interactiva (Swagger UI)**: http://127.0.0.1:8000/docs
- **DocumentaciÃ³n alternativa (ReDoc)**: http://127.0.0.1:8000/redoc

## ğŸ“š Uso de la API

### Endpoint Principal: POST /scrape

Extrae contenido de una URL y lo convierte a markdown organizado.

**URL**: `http://localhost:8000/scrape`

**MÃ©todo**: `POST`

**Body**:

```json
{
  "url": "https://example.com"
}
```

**Respuesta**:

```json
{
  "url": "https://example.com",
  "title": "TÃ­tulo de la pÃ¡gina",
  "markdown_content": "# TÃ­tulo\n\nContenido en markdown...",
  "metadata": {
    "title": "TÃ­tulo de la pÃ¡gina",
    "content_length": 1500,
    "images_count": 5,
    "links_count": 20,
    "amounts_found": 3,
    "has_tables": true,
    "has_lists": true,
    "headings_count": 8
  },
  "images": [
    "https://example.com/image1.jpg",
    "https://example.com/image2.png"
  ],
  "links": [
    {
      "text": "Enlace ejemplo",
      "url": "https://example.com/link"
    }
  ],
  "amounts": ["$1,000.50", "â‚¬500.00", "1,200 USD"],
  "structured_data": {
    "tables": [
      [
        ["Header 1", "Header 2"],
        ["Row 1 Col 1", "Row 1 Col 2"]
      ]
    ],
    "lists": [["Item 1", "Item 2", "Item 3"]],
    "headings": {
      "h1": ["TÃ­tulo Principal"],
      "h2": ["SubtÃ­tulo 1", "SubtÃ­tulo 2"]
    },
    "contact_info": {
      "emails": ["contact@example.com"],
      "phones": ["+1-234-567-8900"]
    },
    "dates": ["2025-06-22", "June 22, 2025"]
  }
}
```

### Otros Endpoints

**GET /health** - Health check de la API

```bash
curl http://localhost:8000/health
```

**GET /** - Endpoint de bienvenida

```bash
curl http://localhost:8000/
```

## ğŸ”§ Ejemplos de Uso

### Ejemplo con cURL

```bash
curl -X POST "http://localhost:8000/scrape" \
     -H "Content-Type: application/json" \
     -d '{"url": "https://example.com"}'
```

### Ejemplo con Python

```python
import requests

response = requests.post(
    "http://localhost:8000/scrape",
    json={"url": "https://example.com"}
)

if response.status_code == 200:
    data = response.json()
    print(f"TÃ­tulo: {data['title']}")
    print(f"Contenido: {data['markdown_content'][:200]}...")
    print(f"Montos encontrados: {data['amounts']}")
```

### Ejemplo con JavaScript

```javascript
fetch("http://localhost:8000/scrape", {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
  },
  body: JSON.stringify({
    url: "https://example.com",
  }),
})
  .then((response) => response.json())
  .then((data) => {
    console.log("TÃ­tulo:", data.title);
    console.log("Contenido:", data.markdown_content);
    console.log("Montos:", data.amounts);
  });
```

## ğŸ¯ CaracterÃ­sticas del Procesamiento

### ExtracciÃ³n Inteligente

- **Montos y Cantidades**: Detecta automÃ¡ticamente precios, cantidades y valores monetarios
- **Fechas**: Identifica fechas en mÃºltiples formatos
- **Contactos**: Extrae emails y nÃºmeros de telÃ©fono
- **Estructura**: Organiza tablas, listas y encabezados

### Limpieza de Contenido

- Elimina elementos innecesarios (scripts, estilos, navegaciÃ³n)
- Prioriza contenido principal (main, article)
- Convierte a markdown limpio y legible

### Optimizado para LLM

- Estructura jerÃ¡rquica clara
- Datos organizados en categorÃ­as
- Formato markdown estÃ¡ndar
- Metadatos descriptivos

## ğŸ³ Docker

El proyecto incluye configuraciÃ³n completa de Docker con:

- InstalaciÃ³n automÃ¡tica de dependencias del sistema
- ConfiguraciÃ³n de Playwright y navegadores
- OptimizaciÃ³n para contenedores

## ğŸ“ Desarrollo

Para ejecutar en modo desarrollo:

```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

Para probar la API:

```bash
python test_api.py
```

## ğŸ“„ DocumentaciÃ³n API

La documentaciÃ³n interactiva estÃ¡ disponible en:

- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ”’ Seguridad

- ValidaciÃ³n estricta de URLs
- Timeout configurado para peticiones
- SanitizaciÃ³n de contenido HTML
- LÃ­mites en cantidad de datos extraÃ­dos

## ğŸš€ Deployment

Para producciÃ³n, considera:

- Variables de entorno para configuraciÃ³n
- Proxy reverso (nginx)
- Monitoreo y logs
- Escalado horizontal

## ğŸ“ Soporte

Para reportar bugs o solicitar caracterÃ­sticas, crea un issue en el repositorio.
